{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Immothep\n",
    "\n",
    "### La société Immothep est une agence immobilière spécialisée dans le vente de biens de particuliers.\n",
    "\n",
    "Possédant déjà un site internet, elle souhaite pouvoir intégrer à celui-ci, un module d'estimation. Elle possède les ressources nécessaires pour réaliser le code dit \"front\", ainsi que les ressources graphiques.\n",
    "\n",
    "Elle ne possède cependant pas les compétences nécessaires pour la réalisation de l'API qui va permettre d'exposer ce nouveau service.\n",
    "\n",
    "La société vous sollicite donc pour réaliser la partie API en utilisant les données Open Data des Demandes de Valeurs Foncières (DVF) sur l'année 2019.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 0. Initialisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.join(os.getcwd(), '..')\n",
    "\n",
    "DATA_IN_FOLDER = os.path.join(cwd, 'data', 'in')\n",
    "DATA_CURATED_FOLDER = os.path.join(cwd, 'data', 'curated')\n",
    "DATA_OUT_FOLDER = os.path.join(cwd, 'data', 'out')\n",
    "DATA_REPORTS_FOLDER = os.path.join(cwd, 'data', 'reports')\n",
    "DATASOURCE_PATH = r'https://www.data.gouv.fr/fr/datasets/r/3004168d-bec4-44d9-a781-ef16f41856a2'\n",
    "FILE_NAME = 'valeursfoncieres-2019.txt'"
   ]
  },
  {
   "source": [
    "### 1. Load dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already downloaded\n"
     ]
    }
   ],
   "source": [
    "global_datasource_src = os.path.join(DATASOURCE_PATH)\n",
    "global_datasource_dest = os.path.join(DATA_IN_FOLDER, FILE_NAME)\n",
    "\n",
    "if os.path.exists(global_datasource_dest):\n",
    "    print('Data already downloaded')\n",
    "else :\n",
    "    print('Download %s' % global_datasource_src)\n",
    "    with open(global_datasource_dest, \"wb\") as f:\n",
    "        response = requests.get(global_datasource_src, stream=True)\n",
    "        f.write(response.content)\n",
    "        print('Data downloaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "global_data = pd.read_csv(global_datasource_dest, encoding='utf-8', sep='|', decimal=',')"
   ]
  },
  {
   "source": [
    "### 2. Exploratory Data Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                count           mean           std      min  \\\n",
      "Code service CH                   0.0            NaN           NaN      NaN   \n",
      "Reference document                0.0            NaN           NaN      NaN   \n",
      "1 Articles CGI                    0.0            NaN           NaN      NaN   \n",
      "2 Articles CGI                    0.0            NaN           NaN      NaN   \n",
      "3 Articles CGI                    0.0            NaN           NaN      NaN   \n",
      "4 Articles CGI                    0.0            NaN           NaN      NaN   \n",
      "5 Articles CGI                    0.0            NaN           NaN      NaN   \n",
      "No disposition              2535791.0       1.199535  7.401537e+00     1.00   \n",
      "Valeur fonciere             2506530.0  971597.040251  7.856914e+06     0.01   \n",
      "No voie                     1510153.0     727.027501  2.076794e+03     1.00   \n",
      "Code postal                 2507468.0   51976.369473  2.730261e+04  1000.00   \n",
      "Code commune                2535791.0     208.996930  1.670737e+02     1.00   \n",
      "Prefixe de section           126835.0     459.484574  3.260987e+02     1.00   \n",
      "No plan                     2535791.0     403.790847  5.546664e+02     1.00   \n",
      "Surface Carrez du 1er lot    221065.0      60.976915  9.191766e+01     0.14   \n",
      "Surface Carrez du 2eme lot    54274.0      63.399269  5.886704e+01     0.13   \n",
      "Surface Carrez du 3eme lot     5214.0      73.177908  9.046654e+01     0.85   \n",
      "4eme lot                       9236.0     113.200195  5.230737e+02     2.00   \n",
      "Surface Carrez du 4eme lot     1415.0      86.964148  1.462351e+02     1.00   \n",
      "5eme lot                       4427.0     113.961373  4.529716e+02     2.00   \n",
      "Surface Carrez du 5eme lot      609.0      94.380181  1.132562e+02     0.89   \n",
      "Nombre de lots              2535791.0       0.394333  8.086631e-01     0.00   \n",
      "Code type local             1353332.0       1.989685  9.438622e-01     1.00   \n",
      "Identifiant local                 0.0            NaN           NaN      NaN   \n",
      "Surface reelle bati         1351615.0      87.756540  8.728312e+02     0.00   \n",
      "Nombre pieces principales   1351615.0       2.430351  2.083948e+00     0.00   \n",
      "Surface terrain             1742833.0    3092.532778  1.364341e+04     0.00   \n",
      "\n",
      "                                  25%       50%          75%           max  \n",
      "Code service CH                   NaN       NaN          NaN           NaN  \n",
      "Reference document                NaN       NaN          NaN           NaN  \n",
      "1 Articles CGI                    NaN       NaN          NaN           NaN  \n",
      "2 Articles CGI                    NaN       NaN          NaN           NaN  \n",
      "3 Articles CGI                    NaN       NaN          NaN           NaN  \n",
      "4 Articles CGI                    NaN       NaN          NaN           NaN  \n",
      "5 Articles CGI                    NaN       NaN          NaN           NaN  \n",
      "No disposition                  1.000       1.0       1.0000  6.940000e+02  \n",
      "Valeur fonciere             60000.000  149000.0  269000.0000  2.086000e+09  \n",
      "No voie                         8.000      24.0      87.0000  9.999000e+03  \n",
      "Code postal                 31230.000   50200.0   77144.0000  9.749000e+04  \n",
      "Code commune                   76.000     174.0     300.0000  9.090000e+02  \n",
      "Prefixe de section            166.000     331.0     829.0000  9.500000e+02  \n",
      "No plan                        87.000     223.0     504.0000  9.762000e+03  \n",
      "Surface Carrez du 1er lot      33.700      52.9      72.6700  9.646200e+03  \n",
      "Surface Carrez du 2eme lot     42.750      60.6      76.0400  8.630000e+03  \n",
      "Surface Carrez du 3eme lot     38.105      60.6      85.1875  3.583640e+03  \n",
      "4eme lot                        7.000      24.0      68.0000  1.701400e+04  \n",
      "Surface Carrez du 4eme lot     30.510      61.9     100.2750  3.208900e+03  \n",
      "5eme lot                        8.000      27.0      73.0000  1.104600e+04  \n",
      "Surface Carrez du 5eme lot     23.790      65.0     116.1000  1.029550e+03  \n",
      "Nombre de lots                  0.000       0.0       1.0000  1.750000e+02  \n",
      "Code type local                 1.000       2.0       3.0000  4.000000e+00  \n",
      "Identifiant local                 NaN       NaN          NaN           NaN  \n",
      "Surface reelle bati            15.000      60.0      94.0000  3.129620e+05  \n",
      "Nombre pieces principales       0.000       3.0       4.0000  6.700000e+01  \n",
      "Surface terrain               233.000     610.0    1885.0000  1.662560e+06  \n",
      "Nb records 2535791\n",
      "Nb columns 43\n",
      "Data types [dtype('float64') dtype('int64') dtype('O')]\n",
      "Nb empty columns 8\n",
      "Initial report already generated at c:\\prairie\\projet8-v2\\Immothep\\src\\..\\data\\reports\\rapport_initial.html\n"
     ]
    }
   ],
   "source": [
    "#basic stats about data\n",
    "print(global_data.describe().transpose())\n",
    "# Check the number of data points in the data set\n",
    "print(f'Nb records {len(global_data)}')\n",
    "# Check the number of features in the data set\n",
    "print(f'Nb columns {len(global_data.columns)}')\n",
    "# Check the data types\n",
    "print(f'Data types {global_data.dtypes.unique()}')\n",
    "\n",
    "#count empty columns\n",
    "tmp_data = global_data.dropna(axis = 1, how ='all') \n",
    "print(f'Nb empty columns {len(global_data.columns) - len(tmp_data.columns)}')\n",
    "del(tmp_data)\n",
    "\n",
    "#deep analysis\n",
    "profil = ProfileReport(global_data)\n",
    "#set True to force update of file\n",
    "if os.path.exists(os.path.join( DATA_REPORTS_FOLDER ,'rapport_initial.html') or False): \n",
    "    print('Initial report already generated at ' + os.path.join( DATA_REPORTS_FOLDER ,'rapport_initial.html'))    \n",
    "else :\n",
    "    profil.to_file(output_file= os.path.join( DATA_REPORTS_FOLDER ,'rapport_initial.html'))\n",
    "\n",
    "del(profil)"
   ]
  },
  {
   "source": [
    "### 3. Global cleanup of the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New number of column 35/43\n",
      "New number of row 2439667/2535791\n"
     ]
    }
   ],
   "source": [
    "#clean up data - remove empty columns\n",
    "cleared_data = global_data.dropna(axis = 1, how ='all') \n",
    "print(f'New number of column {len(cleared_data.columns)}/{len(global_data.columns)}')\n",
    "\n",
    "#remove duplicates rows\n",
    "cleared_data.drop_duplicates(inplace=True)\n",
    "print(f'New number of row {len(cleared_data)}/{len(global_data)}')\n"
   ]
  },
  {
   "source": [
    "#### > Create property referential (house, appartment, ground, ...)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create property referential\n",
    "global_property_type = cleared_data[['Code type local','Type local']]\n",
    "global_property_type.drop_duplicates(inplace=True)\n",
    "global_property_type.dropna(inplace=True)\n",
    "\n",
    "#add 'Autre' property type\n",
    "global_property_type.loc[len(global_property_type)] = [len(global_property_type)+1,'Autre']\n",
    "\n",
    "global_property_type.sort_values(by=['Code type local'], inplace=True)\n",
    "global_property_type.set_index('Code type local')\n",
    "global_property_type['Code type local'] = global_property_type['Code type local'].astype(int)\n",
    "\n",
    "global_property_type.to_csv(os.path.join(DATA_OUT_FOLDER, 'property_type_referential.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Valeur fonciere\n",
       "Nombre de lots                 \n",
       "0                       1636095\n",
       "1                        615030"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Valeur fonciere</th>\n    </tr>\n    <tr>\n      <th>Nombre de lots</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1636095</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>615030</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "# drop sells with more than one lot\n",
    "cleared_data.drop(cleared_data.loc[cleared_data[\"Nombre de lots\"]> 1].index, inplace=True)\n",
    "cleared_data.groupby(\"Nombre de lots\")[['Valeur fonciere']].count().sort_values(\"Nombre de lots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New number of column 11/43\nNew number of records 2251125/2535791\n"
     ]
    }
   ],
   "source": [
    "#drop unused columns\n",
    "cleared_data.drop(columns=['No disposition','Date mutation','No voie','B/T/Q','Type de voie','Code voie','Voie','Prefixe de section','Section','No plan','No Volume','1er lot','Surface Carrez du 1er lot','2eme lot','Surface Carrez du 2eme lot','3eme lot','Surface Carrez du 3eme lot','4eme lot','Surface Carrez du 4eme lot','5eme lot','Surface Carrez du 5eme lot','Nombre de lots','Commune', 'Type local'], inplace=True, errors='ignore')\n",
    "\n",
    "#drop rows with empty sales costs\n",
    "cleared_data.dropna(subset = ['Valeur fonciere'], inplace = True) \n",
    "\n",
    "print(f'New number of column {len(cleared_data.columns)}/{len(global_data.columns)}')\n",
    "print(f'New number of records {len(cleared_data)}/{len(global_data)}')"
   ]
  },
  {
   "source": [
    "#### > from additionnal referential, create our own to get gps coordinates and insee code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gps coordinates referential already exists at c:\\prairie\\projet8-v2\\Immothep\\src\\..\\data\\in\\correspondance-code-insee-code-postal.csv\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(DATA_OUT_FOLDER, 'coord_gps_referential.csv')):\n",
    " print('gps coordinates referential already exists at '+ os.path.join(DATA_IN_FOLDER, 'correspondance-code-insee-code-postal.csv'))\n",
    "else :\n",
    "    #load insee referential\n",
    "    cp = pd.read_csv(os.path.join(DATA_IN_FOLDER, 'correspondance-code-insee-code-postal.csv'), encoding='utf-8', sep=';', usecols=['Code Commune', 'Code Département', 'Code Postal', 'geo_point_2d', 'Code INSEE'])\n",
    "\n",
    "    # Create two lists for the loop results to be placed\n",
    "    lat = []\n",
    "    lon = []\n",
    "\n",
    "    # For each row in a varible,\n",
    "    for row in cp['geo_point_2d']:\n",
    "        lat.append(row.split(',')[0])\n",
    "        lon.append(row.split(',')[1])\n",
    "    \n",
    "    # Create two new columns from lat and lon\n",
    "    cp['Latitude'] = lat\n",
    "    cp['Longitude'] = lon\n",
    "\n",
    "    #split multiple cp in one row to n rows\n",
    "    df = cp['Code Postal'].str.split('/').apply(Series, 1).stack()\n",
    "    df.index = df.index.droplevel(-1) # to line up with df's index\n",
    "    df.name = 'Code Postal'\n",
    "    del(cp['Code Postal'])\n",
    "    cp = cp.join(df)\n",
    "    \n",
    "    cp.to_csv(os.path.join(DATA_OUT_FOLDER, 'coord_gps_referential.csv'), sep=';', index=False, columns= ['Code INSEE', 'Code Postal', 'Code Commune', 'Code Département', 'Latitude', 'Longitude'])\n",
    "    \n",
    "    del(lat, lon)    \n",
    "    del(cp)\n",
    "    del(df)\n"
   ]
  },
  {
   "source": [
    "#### > Fill-up missing postal code then add gps coordinates to sells"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.read_csv(os.path.join(DATA_OUT_FOLDER, 'coord_gps_referential.csv'), encoding='utf-8', sep=';')\n",
    "cp['Code Commune'] = cp['Code Commune'].astype(int)\n",
    "cp['Code Département'] = cp['Code Département'].astype(str)\n",
    "cleared_data['Code commune'] = cleared_data['Code commune'].astype(int)\n",
    "cleared_data['Code departement'] = cleared_data['Code departement'].astype(str)\n",
    "\n",
    "cleared_data = pd.merge(cleared_data, cp, how='inner', left_on=['Code commune','Code departement'], right_on = ['Code Commune','Code Département'])\n",
    "\n",
    "cleared_data.drop(columns=['Code INSEE', 'Code postal', 'Code departement', 'Code commune','Code Commune', 'Code Département', 'Code Postal'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleaned rows : 228953\n0          1.0\n1          1.0\n2          1.0\n3          5.0\n4          5.0\n          ... \n2407036    4.0\n2407037    4.0\n2407038    4.0\n2407039    4.0\n2407040    2.0\nName: Code type local, Length: 2178088, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Clear data without transaction type\n",
    "counter = len(cleared_data)\n",
    "cleared_data.drop(cleared_data[(pd.isna(cleared_data['Code type local'])) & (pd.isna(cleared_data['Nature culture']))].index, inplace=True)\n",
    "print(f'Cleaned rows : {counter - len(cleared_data)}')\n",
    "\n",
    "#set 'Autre' value to empty 'Code type local'\n",
    "other_type = int(global_property_type[global_property_type['Type local'] == 'Autre']['Code type local'])\n",
    "\n",
    "cleared_data['Code type local'] = cleared_data['Code type local'].fillna(other_type)\n",
    "print(cleared_data['Code type local'])\n",
    "\n",
    "cleared_data.drop(columns=['Nature culture', 'Nature culture speciale'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete missing data with 0\n",
    "cleared_data[['Surface reelle bati','Nombre pieces principales', 'Surface terrain']] = cleared_data[['Surface reelle bati','Nombre pieces principales', 'Surface terrain']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maison - 513516\n",
      "Appartement - 306925\n",
      "Dépendance - 346028\n",
      "Local industriel. commercial ou assimilé - 90393\n",
      "Autre - 921226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#force data type\n",
    "cleared_data['Code type local'] = cleared_data['Code type local'].astype(int)\n",
    "cleared_data['Surface reelle bati'] = cleared_data['Surface reelle bati'].astype(int)\n",
    "cleared_data['Nombre pieces principales'] = cleared_data['Nombre pieces principales'].astype(int)\n",
    "cleared_data['Surface terrain'] = cleared_data['Surface terrain'].astype(int)\n",
    "cleared_data['Latitude'] = cleared_data['Latitude'].astype(float)\n",
    "cleared_data['Longitude'] = cleared_data['Longitude'].astype(float)\n",
    "\n",
    "#reorder columns\n",
    "cleared_data = cleared_data[['Nature mutation', 'Code type local', 'Valeur fonciere', 'Latitude', 'Longitude', 'Surface reelle bati', 'Nombre pieces principales', 'Surface terrain']]\n",
    " \n",
    "#save data by property type\n",
    "for type in global_property_type.values:\n",
    "    property_by_type = cleared_data[cleared_data['Code type local'] == type[0]]\n",
    "    print(type[1] + ' - ' + str(len(property_by_type)))\n",
    "    #print(f'nb {global_property_type['type local']} is {len(property_by_type)}')\n",
    "    filename = str.format(f'{type[1]}_valeursfoncieres.csv')\n",
    "    property_by_type.to_csv(os.path.join(DATA_CURATED_FOLDER, filename), sep=';', index=False )\n",
    "    del(property_by_type)\n"
   ]
  },
  {
   "source": [
    "### 5. Global cleanup - post analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final report already generated at c:\\prairie\\projet8-v2\\Immothep\\src\\..\\data\\reports\\rapport_final.html\n"
     ]
    }
   ],
   "source": [
    "#deep analysis\n",
    "profil = ProfileReport(cleared_data)\n",
    "#set True to force update of file\n",
    "if os.path.exists(os.path.join( DATA_REPORTS_FOLDER ,'rapport_final.html') or False):\n",
    "    print('Final report already generated at ' + os.path.join( DATA_REPORTS_FOLDER ,'rapport_final.html'))   \n",
    "else :\n",
    "    profil.to_file(output_file= os.path.join( DATA_REPORTS_FOLDER ,'rapport_final.html'))\n",
    "\n",
    "del(profil)"
   ]
  }
 ]
}